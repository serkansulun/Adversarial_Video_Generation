import os
import numpy as np
from skimage.transform import resize
from math import log
from copy import deepcopy

from torchvision.utils import save_image
import torch
from torch.nn.functional import conv2d
import torch.nn as nn

import constants as c


def save_samples(history, gt, generation, epoch, mode):

    # Save sample images
    n = 4  # number of samples to save
    n = min(n, history[-1].shape[0])

    history = history[-1][:n]
    gt = gt[-1][:n]
    generation = generation[-1][:n]
    image = deepcopy(history[:, :c.CHANNELS, :, :])     # first frame
    for i in range(1, c.HIST_LEN):
        image = torch.cat([image, history[:, i*c.CHANNELS:(i+1)*c.CHANNELS, :, :]], 3)  # add rest of history
    image = torch.cat([image, torch.ones((n, c.CHANNELS, c.HEIGHT, 5))], 3)   # add a black line
    for i in range(c.PRED_LEN):
        image = torch.cat([image, gt[:, i*c.CHANNELS:(i+1)*c.CHANNELS, :, :]], 3)  # add ground-truth
    image = torch.cat([image, torch.ones((n, c.CHANNELS, c.HEIGHT, 5))], 3)   # add a black line
    for i in range(c.PRED_LEN):
        image = torch.cat([image, generation[:, i*c.CHANNELS:(i+1)*c.CHANNELS, :, :]], 3)  # add generation

    # img = torch.add(img, -torch.min(sequence))
    # img = torch.mul(img, 1/torch.max(sequence))
    image = torch.add(image, 1)
    image = torch.mul(image, 0.5)

    save_image(image.data, c.IMG_SAVE_DIR + mode + '_e' + str(epoch) + '.png', nrow=1, normalize=True)


def normalize_frames(frames):
    """
    Convert frames from int8 [0, 255] to float32 [-1, 1].

    @param frames: A numpy array. The frames to be converted.

    @return: The normalized frames.
    """
    new_frames = frames.astype(np.float32)
    new_frames /= (255.0 / 2)
    new_frames -= 1

    return new_frames



def log10(x):
    return torch.log(x)/log(10)


def calculate_psnr(gen_frames, gt_frames):
    # Move values between 0 and 2
    gen_frames = torch.add(gen_frames, 1)
    gt_frames = torch.add(gt_frames, 1)
    max_value = 2.0

    shape = gen_frames.shape
    num_pixels = shape[1] * shape[2] * shape[3]
    mse = ((gt_frames - gen_frames)**2).sum(1).sum(1).sum(1) / num_pixels
    batch_errors = 10 * log10(max_value ** 2 / mse)
    return torch.mean(batch_errors)

def calculate_sharp_psnr(gen_frames, gt_frames):
    """
    Computes the Sharpness Difference error between the generated images and the ground truth
    images.

    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the
                       generator model.
    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for
                      each frame in gen_frames.

    @return: A scalar tensor. The Sharpness Difference error over each frame in the batch.
    """
    gen_frames = torch.add(gen_frames, 1)
    gt_frames = torch.add(gt_frames, 1)
    max_value = 2.0

    shape = gen_frames.shape
    num_pixels = shape[1] * shape[2] * shape[3]
    # gradient difference
    # create filters [-1, 1] and [[1],[-1]] for diffing to the left and down respectively.
    # TODO: Could this be simplified with one filter [[-1, 2], [0, -1]]?
    pos = torch.from_numpy(np.identity(c.CHANNELS, dtype=np.float32))
    if c.CUDA:
        pos = pos.cuda()
    neg = -1 * pos
    filter_x = torch.stack([neg, pos], dim=2)#.unsqueeze(2)  # [-1, 1]
    filter_x_2d = torch.stack([filter_x, filter_x], dim=2)
    filter_y = torch.stack([neg, pos], dim=2)#.unsqueeze(-1)  # [[1],[-1]]
    filter_y_2d = torch.stack([filter_x, filter_x], dim=3)

    gen_dx = torch.abs(conv2d(gen_frames, filter_x_2d))
    gen_dy = torch.abs(conv2d(gen_frames, filter_y_2d))
    gt_dx = torch.abs(conv2d(gt_frames, filter_x_2d))
    gt_dy = torch.abs(conv2d(gt_frames, filter_y_2d))

    gen_grad_sum = gen_dx + gen_dy
    gt_grad_sum = gt_dx + gt_dy

    grad_diff = torch.abs(gt_grad_sum - gen_grad_sum)

    batch_errors = 10 * log10(max_value**2 / ((1.0 / num_pixels) * grad_diff.sum(1).sum(1).sum(1)))
    return torch.mean(batch_errors)



class Flatten(nn.Module):
    def forward(self, x):
        x = x.view(x.size()[0], -1)
        return x


def conv_out_size(input, padding, kernel, stride):
    return int(((input + (2 * padding) - kernel) / stride) + 1)


def scale_batch(batch):

    output_all_scales = []
    n_batch, n_features, height, width = batch.shape
    for scale_num in range(c.NUM_SCALE_NETS):

        scale_factor = 1. / 2 ** ((c.NUM_SCALE_NETS - 1) - scale_num)
        scale_height = int(c.HEIGHT * scale_factor)
        scale_width = int(c.WIDTH * scale_factor)
        output_single_scale = np.zeros([n_batch, n_features, scale_height, scale_width], dtype=np.float32)

        n_channels = c.CHANNELS
        n_frames = n_features / n_channels

        for ind_batch, minibatch in enumerate(batch):
            for ind_frame in range(n_frames):
                frame = batch[ind_batch, ind_frame*n_channels:(ind_frame+1)*n_channels, :, :]
                frame_resized = resize_frame(frame, (scale_height, scale_width))
                output_single_scale[ind_batch, ind_frame*n_channels:(ind_frame+1)*n_channels, :, :] = frame_resized
        output_all_scales.append(output_single_scale)

    return output_all_scales

def resize_frame(frame, (height, width)):
    if frame.shape[0] == 1 and c.CHANNELS > 1:
        frame = np.squeeze(frame)
    frame = np.transpose(frame, [1, 2, 0])
    frame_resized = resize(frame, (height, width))
    frame_resized = np.transpose(frame_resized, [2, 0, 1])
    frame_resized = np.expand_dims(frame_resized, axis=0)
    return frame_resized

def num2str(num, n):
    # Pads zeros and converts to string
    string = str(num)
    while len(string) < n:
        string = '0' + string
    return string

def var2np(x):
    if x.shape == ():
        return x.detach().cpu().item()
    else:
        return x.detach().cpu().numpy()


class RunningAverage:

    def __init__(self):

        self.average = {}
        self.counter = 0

    def update(self, performance):
        for key in performance.keys():
            if key in self.average.keys():
                # take moving average
                self.average[key] = (self.average[key] * self.counter + var2np(performance[key])) / (self.counter + 1)
            else:
                self.average[key] = var2np(performance[key])
        self.counter += 1

    def values(self):
        return self.average





